# -*- coding: utf-8 -*-
"""hw3(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lh65dTB7Gw923N0NlCwD5jATZp7FR7qq

**Install requirements**
"""

#!pip3 install 'torch==1.3.1'
#!pip3 install 'torchvision==0.5.0'
!pip3 install 'Pillow-SIMD'
!pip3 install 'tqdm'

torch.cuda.empty_cache()

from google.colab import drive
drive.mount('/content/drive')

"""**Import libraries**"""

import os
import logging

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Subset, DataLoader, ConcatDataset
from torch.backends import cudnn

import torchvision
from torchvision import transforms
from torchvision.models import alexnet

from PIL import Image
from tqdm import tqdm
try:
  import tensorboardX
except:
  !pip3 install tensorboardX
  import tensorboardX

import numpy as np

import matplotlib.pyplot as plt
import matplotlib

"""**Set Arguments**"""

DEVICE = 'cuda' # 'cuda' or 'cpu'

#NUM_CLASSES = 7 # 101 + 1: There is am extra Background class that should be removed 

BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing
                     # the batch size, learning rate should change by the same factor to have comparable results

LR = 1e-2            # The initial Learning Rate
MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD
WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default
ALPHA = 0.1         # Parameter multiplied by backpropagation of the reversed layer

NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)
STEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)
GAMMA = 0.1          # Multiplicative factor for learning rate step-down

LOG_FREQUENCY = 10

NUM_DOMAINS = 2

"""**Define Data Preprocessing**"""

# Define transforms for training phase
train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256
                                      transforms.CenterCrop(224),  # Crops a central square patch of the image
                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!
                                                                   # Remember this when applying different transformations, otherwise you get an error
                                      #transforms.RandomCrop( 64 , padding =2) ,
                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor
                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalizes tensor with mean and standard deviation
])
# Define transforms for the evaluation phase
eval_transform = transforms.Compose([transforms.Resize(256),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),                                    
])

"""**Prepare Dataset**"""

# Clone github repository with data
if not os.path.isdir('./Homework3-PACS'):
  !git clone https://github.com/MachineLearning2020/Homework3-PACS

DATA_DIR = 'Homework3-PACS/PACS'

# Prepare Pytorch train/test Datasets
src_dataset = torchvision.datasets.ImageFolder(DATA_DIR+"/photo", transform=train_transform)
src_distribution = {}
for img,label in src_dataset:
  src_distribution[label] = src_distribution.get(label,0) + 1
print(src_distribution.keys())
NUM_CLASSES = len(src_distribution.keys())
plt.figure(figsize=(18, 15))
plt.bar(src_distribution.keys(),src_distribution.values(),)
plt.xticks(rotation='vertical')
plt.show()

target_dataset = torchvision.datasets.ImageFolder(DATA_DIR+"/art_painting", transform=eval_transform)
target_distribution = {}
for img,label in src_dataset:
  target_distribution[label] = target_distribution.get(label,0) + 1
plt.figure(figsize=(18, 15))
plt.bar(target_distribution.keys(),target_distribution.values(),)
plt.xticks(rotation='vertical')
plt.show()
#train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]
#test_indexes = [idx for idx in range(len(test_dataset)) if not idx % 5]

#train_dataset = Subset(train_dataset, train_indexes)
#test_dataset = Subset(test_dataset, test_indexes)

# Check dataset sizes
print('Source Dataset: {}'.format(len(src_dataset)))
print('Target Dataset: {}'.format(len(target_dataset)))

src_dataset.__getitem__(7)

"""**Prepare Dataloaders**"""

# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)
src_dataloader = DataLoader(src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

def imshow(img):
    plt.figure(figsize=(15, 12))
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

    plt.show()


# get some random training images
dataiter = iter(src_dataloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images[:16]))


# get some random training images
dataiter = iter(target_dataloader)
images, labels = dataiter.next()

# show images
imshow(torchvision.utils.make_grid(images[:16]))

"""**Prepare Network**

**Prepare Training**

**Train (no DANN)**
"""

# By default, everything is loaded to cpu

def train(net,train_dataloader,val_dataloader,checkpoint_path):
  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
  n_epochs_stop = 8
  min_val_loss = float('inf')
  epochs_no_improve = 0
  cudnn.benchmark # Calling this optimizes runtime
  train_loss , train_accuracy = [], []
  val_loss , val_accuracy = [], []

  current_step = 0
  # Start iterating over the epochs
  for epoch in range(NUM_EPOCHS):
    val_running_loss = 0.0
    val_running_correct = 0
    train_running_loss = 0.0
    train_running_correct = 0
    train_NUM_BATCHES = 0
    val_NUM_BATCHES = 0
    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))
    net.train(True)
    # Iterate over the dataset
    for images, labels in train_dataloader:  ##---------------------------------  TRAINING
      train_NUM_BATCHES += 1
      # Bring data over the device of choice
      images = images.to(DEVICE)
      labels = labels.to(DEVICE)

      net.train() # Sets module in training mode

      # PyTorch, by default, accumulates gradients after each backward pass
      # We need to manually set the gradients to zero before starting a new iteration
      optimizer.zero_grad() # Zero-ing the gradients

      # Forward pass to the network
      outputs = net(images)

      # Compute loss based on output and ground truth
      loss = criterion(outputs, labels)

      train_running_loss += loss.item()
      _, preds = torch.max(outputs.data, 1)
      train_running_correct += torch.sum(preds == labels.data).data.item()
      # Log loss
      if current_step % LOG_FREQUENCY == 0:
        print('Step {}, Loss {}'.format(current_step, loss.item()))

      # Compute gradients for each layer and update weights
      loss.backward()  # backward pass: computes gradients
      optimizer.step() # update weights based on accumulated gradients
      

      current_step += 1


    net.train(False) # Set Network to evaluation mode
    for val_images, val_labels in tqdm(val_dataloader): ##----------------------  VALIDATION
      val_NUM_BATCHES += 1
      val_images = val_images.to(DEVICE)
      val_labels = val_labels.to(DEVICE)

      # Forward Pass
      outputs = net(val_images)
      loss = criterion(outputs, val_labels)
      # Get predictions
      _, preds = torch.max(outputs.data, 1)

      # Update Corrects
      val_running_correct += torch.sum(preds == val_labels.data).data.item()

      val_running_loss += loss.item()

    print()
    epoch_train_loss = train_running_loss/train_NUM_BATCHES
    epoch_train_accuracy = train_running_correct/float(len(src_dataset))
    print(f"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_accuracy:.2f}")
    epoch_val_loss = val_running_loss/val_NUM_BATCHES
    epoch_val_accuracy = val_running_correct / float(len(target_dataset))
    print(f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_accuracy:.2f}')
    train_loss.append(epoch_train_loss)
    train_accuracy.append(epoch_train_accuracy)
    val_loss.append(epoch_val_loss)
    val_accuracy.append(epoch_val_accuracy)
    # Step the scheduler
    scheduler.step() 
    print()
    print()


    # If the validation loss is at a minimum
    if epoch_val_loss < min_val_loss:
      # Save the model
      torch.save(net, checkpoint_path)
      epochs_no_improve = 0
      min_val_loss = epoch_val_loss

  net = torch.load(checkpoint_path)
  return train_loss,train_accuracy,val_loss,val_accuracy,net
  
def print_acc_loss(train_loss,train_accuracy,val_loss,val_accuracy,title, label1 = 'train accuracy', label2 = 'validation accuracy', label3 = 'train loss',label4= 'validation loss'):
  print(list(zip(train_loss,train_accuracy)),list(zip(val_loss,val_accuracy)))
  # accuracy plots
  plt.figure(figsize=(10, 7))
  plt.plot(train_accuracy, color='green', label=label1)
  plt.plot(val_accuracy, color='blue', label=label2)
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.savefig(title+'_accuracy.png')
  plt.show()

  # loss plots
  plt.figure(figsize=(10, 7))
  plt.plot(train_loss, color='orange', label=label3)
  plt.plot(val_loss, color='red', label=label4)
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()
  plt.savefig(title+'_loss.png')
  plt.show()


def print_DANN_acc_loss(total_loss,total_accuracy,domain_loss,domain_acc,train_loss,train_accuracy,train_domain_loss,train_domain_accuracy,target_domain_loss,target_domain_accuracy,val_loss,val_acc,title):
  # accuracy plots
  plt.figure(figsize=(10, 7))
  plt.plot(total_accuracy, color='green', label='total train accuracy')
  plt.plot(domain_acc, color='gray', label='total domain accuracy')
  plt.plot(train_accuracy, color='blue', label='source class accuracy')
  plt.plot(train_domain_accuracy, color='orange', label='source domain accuracy')
  plt.plot(target_domain_accuracy, color='red', label='target domain accuracy')
  #plt.plot(val_accuracy, color = 'purple', label='target val accuracy')
  plt.xlabel('Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.savefig(title+'_train_accuracies.png')
  plt.show()

  # loss plots
  plt.figure(figsize=(10, 7))
  plt.plot(total_loss, color='green', label='Avg train loss')
  plt.plot(domain_loss, color='gray', label='Avg domain loss')
  plt.plot(train_loss, color='blue', label='source class loss')
  plt.plot(train_domain_loss, color='orange', label='source domain loss')
  plt.plot(target_domain_loss, color='red', label='target domain loss')
  #plt.plot(val_loss, color = 'purple', label='target val loss')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.legend()
  plt.savefig(title+'_train_loss.png')
  plt.show()



def test(net, test_dataloader):
  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
  net.train(False) # Set Network to evaluation mode

  running_corrects = 0
  for images, labels in tqdm(test_dataloader):
    images = images.to(DEVICE)
    labels = labels.to(DEVICE)

    # Forward Pass
    outputs = net(images)

    # Get predictions
    _, preds = torch.max(outputs.data, 1)

    # Update Corrects
    running_corrects += torch.sum(preds == labels.data).data.item()

  # Calculate Accuracy
  accuracy = running_corrects / float(len(target_dataset))

  print('Test Accuracy: {}'.format(accuracy))
  return accuracy

# Define loss function
net = alexnet(pretrained = True)#,num_domains = 2) # Loading AlexNet model
net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy
domain_criterion = nn.CrossEntropyLoss()
# Choose parameters to optimize
# To access a different set of parameters, you have to access submodules of AlexNet
# (nn.Module objects, like AlexNet, implement the Composite Pattern)
# e.g.: parameters of the fully connected layers: net.classifier.parameters()
# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) 
parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet

# Define optimizer
# An optimizer updates the weights based on loss
# We use SGD with momentum
optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)

# Define scheduler
# A scheduler dynamically changes learning rate
# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)

#net = alexnet(pretrained = True,num_classes = NUM_CLASSES)#,num_domains = 2) # Loading AlexNet model

# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes
# We need 101 outputs for Caltech-101
#net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer
                                                 # The convolutional layer is nn.Conv2d

# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs
# It is mandatory to study torchvision.models.alexnet source code

total_params = sum(p.numel() for p in net.parameters())
print(f'{total_params:,} total parameters.')
total_trainable_params = sum(
    p.numel() for p in net.parameters() if p.requires_grad)
print(f'{total_trainable_params:,} training parameters.')

tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="./alexnet_noDANN_pretrained")
print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained")
test(net,target_dataloader)

"""*TRAIN DANN*"""

import torch.nn as nn
from torch.autograd import Function
from torch import hub

class ReverseLayerF(Function):
    # Forwards identity
    # Sends backward reversed gradients
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha

        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha

        return output, None

__all__ = ['AlexNet', 'alexnet']


model_urls = {
    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',
}


class AlexNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )
        self.domain_classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x, alpha=None):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
      
        # If we pass alpha, we can assume we are training the discriminator
        if alpha is not None:
            # gradient reversal layer (backward gradients will be reversed)
            reverse_feature = ReverseLayerF.apply(x, alpha)
            x = self.domain_classifier(x)
            return x
        # If we don't pass alpha, we assume we are training with supervision
        else:
            # do something else
            x = self.classifier(x)
            return x

    def assign_wb(self):

        self.domain_classifier[1].weight.data.copy_(self.classifier[1].weight.data)
        self.domain_classifier[1].bias.data.copy_(self.classifier[1].bias.data)
        self.domain_classifier[4].weight.data.copy_(self.classifier[4].weight.data)
        self.domain_classifier[4].bias.data.copy_(self.classifier[4].bias.data)
        self.domain_classifier[6].weight.data.copy_(self.classifier[6].weight.data)
        self.domain_classifier[6].bias.data.copy_(self.classifier[6].bias.data)


def alexnet(pretrained=False, progress=True, **kwargs):
    r"""AlexNet model architecture from the
    `"One weird trick..." <https://arxiv.org/abs/1404.5997>`_ paper.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    """
    model = AlexNet(**kwargs)
    if pretrained:
        state_dict = hub.load_state_dict_from_url(model_urls['alexnet'],
                                              progress=progress)
        model.load_state_dict(state_dict,strict = False)
        model.assign_wb()
    return model

def train_dann(net,src_dataloader,target_dataloader,checkpoint_path,ALPHA=0.1):
  checkpoint_path = '/content/drive/My Drive'+checkpoint_path[1:]
  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda 
  n_epochs_stop = 5
  min_val_loss = np.Inf
  epochs_no_improve = 0
  cudnn.benchmark # Calling this optimizes runtime
  train_loss , train_accuracy , train_src_domain_loss, train_src_domain_accuracy, train_target_domain_loss, train_target_domain_accuracy = [], [], [], [], [], []
  train_domain_loss, train_domain_accuracy,train_total_loss, train_total_accuracy = [], [], [], []
  val_loss , val_accuracy = [], []

  current_step = 0
  # Start iterating over the epochs
  for epoch in range(NUM_EPOCHS):
    val_running_loss = 0.0
    val_running_correct = 0
    train_running_loss = 0.0
    train_running_correct = 0
    train_running_src_domain_loss = 0.0
    train_running_src_domain_correct = 0
    train_running_target_domain_loss = 0.0
    train_running_target_domain_correct = 0
    train_running_total_loss = 0.0
    train_running_total_correct = 0

    train_NUM_BATCHES = 0
    val_NUM_BATCHES = 0
    print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))
    net.train(True)
    len_dataloader = max(len(src_dataloader), len(target_dataloader))
    data_source_iter = iter(src_dataloader)
    data_target_iter = iter(target_dataloader)
    # Iterate over the dataset
    
    for i in range(len_dataloader): ##------------------------------------------------  TRAINING
      
      #p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader
      #alpha = 2. / (1. + np.exp(-10 * p)) - 1
      # training model using source data

      # loss += criterion

      try:
        data_source = data_source_iter.next()
        src_images, src_labels = data_source
      except StopIteration:
        data_source_iter = iter(src_dataloader)
        src_images, src_labels = next(data_source_iter)
      #i += BATCH_SIZE
      
      # Bring data over the device of choice
      src_images = src_images.to(DEVICE)
      src_labels = src_labels.to(DEVICE)
      domain_src_labels = torch.zeros(BATCH_SIZE,dtype=torch.int64).to(DEVICE)
      train_NUM_BATCHES += 1
      
      net.train() # Sets module in training mode

      # PyTorch, by default, accumulates gradients after each backward pass
      # We need to manually set the gradients to zero before starting a new iteration
      optimizer.zero_grad() # Zero-ing the gradients

      # Forward pass to the network
      outputs = net(src_images)

      # Compute loss based on output and ground truth (of class)----------------    class classification
      loss = criterion(outputs, src_labels)

      train_running_loss += loss.item()
      _, preds = torch.max(outputs.data, 1)
      train_running_correct += torch.sum(preds == src_labels.data).data.item()
      

      # Compute gradients for each layer and update weights
      #loss.backward()  # backward pass: computes gradients
      # end of train label classification
      
      # domain classification src-----------------------------------------------    source domain classification
      domain_src_outputs = net(src_images,alpha = ALPHA)
      domain_src_loss = domain_criterion(domain_src_outputs, domain_src_labels)
      train_running_src_domain_loss += domain_src_loss.item()
      _, dom_src_preds = torch.max(domain_src_outputs.data, 1)
      train_running_src_domain_correct += torch.sum(dom_src_preds == domain_src_labels.data).data.item()
      #domain_src_loss.backward()

      # domain classification target--------------------------------------------    target domain classification
      try:
        data_target = data_target_iter.next()
        target_images, target_labels = data_target
      except StopIteration:
        data_target_iter = iter(target_dataloader)
        target_images, target_labels = next(data_target_iter)
      
      target_images = target_images.to(DEVICE)
      domain_target_labels = torch.ones(BATCH_SIZE,dtype=torch.int64).to(DEVICE)
      domain_target_outputs = net(target_images,alpha = ALPHA)
      domain_target_loss = domain_criterion(domain_target_outputs, domain_target_labels)
      train_running_target_domain_loss += domain_target_loss.item()
      _, dom_target_preds = torch.max(domain_target_outputs.data, 1)
      train_running_target_domain_correct += torch.sum(dom_target_preds == domain_target_labels.data).data.item()
      #domain_target_loss.backward()
      #-------------------------------------------------------------------------    Loss calculus and log
      total_loss = loss + domain_src_loss + domain_target_loss
      total_loss.backward()

      train_running_total_loss += total_loss.item()
      #tot_correct = train_running_correct + train_running_src_domain_correct + train_running_target_domain_correct
      #train_running_total_correct += tot_correct

      optimizer.step()
      current_step += 1
      # Log loss
      #if current_step % LOG_FREQUENCY == 0:
      #  print('ALPHA {}, Step {}, Total Loss {}'.format(ALPHA, current_step, total_loss.item()))
      #  print(f'Source class loss {loss}, Source domain loss {domain_src_loss}, Target domain loss{domain_target_loss}');

    net.train(False) # Set Network to evaluation mode
    for val_images, val_labels in tqdm(target_dataloader): ##----------------------  VALIDATION
      val_NUM_BATCHES += 1
      val_images = val_images.to(DEVICE)
      val_labels = val_labels.to(DEVICE)

      # Forward Pass
      outputs = net(val_images)
      domain_outputs = net(val_images,ALPHA)

      # Get predictions
      _, preds = torch.max(outputs.data, 1)

      # Update Corrects
      val_running_correct += torch.sum(preds == val_labels.data).data.item()

      val_running_loss += loss.item()
    print()
    epoch_train_loss = train_running_loss/float(train_NUM_BATCHES)
    epoch_train_accuracy = train_running_correct/float(len(target_dataset))
    print(f"Source class Loss: {epoch_train_loss:.4f}, Train class Acc: {epoch_train_accuracy:.2f}")
    epoch_val_loss = val_running_loss/float(val_NUM_BATCHES)
    epoch_val_accuracy = val_running_correct / float(len(target_dataset))
    print(f'Target class Loss: {epoch_val_loss:.4f}, Val class Acc: {epoch_val_accuracy:.2f}')
    epoch_train_domain_loss = train_running_src_domain_loss/float(train_NUM_BATCHES)
    epoch_train_domain_accuracy = train_running_src_domain_correct/float(len(target_dataset))
    print(f"Source domain Loss: {epoch_train_domain_loss:.4f}, Source domain Acc: {epoch_train_domain_accuracy:.2f}")
    epoch_target_domain_loss = train_running_target_domain_loss/float(train_NUM_BATCHES)
    epoch_target_domain_accuracy = train_running_target_domain_correct/float(len(target_dataset))
    print(f"Target domain Loss: {epoch_target_domain_loss:.4f}, Target domain Acc: {epoch_target_domain_accuracy:.2f}")
    epoch_train_total_loss = train_running_total_loss/float((train_NUM_BATCHES*3))
    epoch_train_total_accuracy = (train_running_correct + train_running_src_domain_correct + train_running_target_domain_correct)/float(len(target_dataset)*3)
    print(f"Total train Loss: {epoch_train_total_loss:.4f}, Total train Acc: {epoch_train_total_accuracy:.2f}")
    epoch_train_tot_domain_loss = (train_running_src_domain_loss + train_running_target_domain_loss)/float(train_NUM_BATCHES*2)
    epoch_train_tot_domain_accuracy = (train_running_src_domain_correct + train_running_target_domain_correct)/float(len(target_dataset)*2)
    print(f"Total domain Loss: {epoch_train_tot_domain_loss:.4f}, Total domain Acc: {epoch_train_tot_domain_accuracy:.2f}")
    train_loss.append(epoch_train_loss)
    train_accuracy.append(epoch_train_accuracy)
    val_loss.append(epoch_val_loss)
    val_accuracy.append(epoch_val_accuracy)
    train_src_domain_loss.append(epoch_train_domain_loss) 
    train_src_domain_accuracy.append(epoch_train_domain_accuracy) 
    train_target_domain_loss.append(epoch_target_domain_loss) 
    train_target_domain_accuracy.append(epoch_target_domain_accuracy)
    train_total_loss.append(epoch_train_total_loss)
    train_total_accuracy.append(epoch_train_total_accuracy)
    train_domain_loss.append(epoch_train_tot_domain_loss)
    train_domain_accuracy.append(epoch_train_tot_domain_accuracy)
    # Step the scheduler
    scheduler.step() 
    print()
    print()


    # If the validation loss is at a minimum
    if epoch_val_loss < min_val_loss:
      # Save the model
      torch.save(net, checkpoint_path)
      epochs_no_improve = 0
      min_val_loss = epoch_val_loss
      
  net = torch.load(checkpoint_path)
  return train_total_loss,train_total_accuracy,train_domain_loss,train_domain_accuracy,train_loss,train_accuracy,train_src_domain_loss, train_src_domain_accuracy, train_target_domain_loss, train_target_domain_accuracy,val_loss,val_accuracy,net

BATCH_SIZE = 256
src_dataloader = DataLoader(src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
net = alexnet(pretrained=True) # Loading AlexNet model
#net.classifier[1].weight.data 
#model.classifier[1].bias.data
# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes
# We need 101 outputs for Caltech-101
net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer
                                                 # The convolutional layer is nn.Conv2d
net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy
domain_criterion = nn.CrossEntropyLoss()
# Choose parameters to optimize
# To access a different set of parameters, you have to access submodules of AlexNet
# (nn.Module objects, like AlexNet, implement the Composite Pattern)
# e.g.: parameters of the fully connected layers: net.classifier.parameters()
# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) 


parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet

# Define optimizer
# An optimizer updates the weights based on loss
# We use SGD with momentum
optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)

# Define scheduler
# A scheduler dynamically changes learning rate
# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs
# It is mandatory to study torchvision.models.alexnet source code
totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN",ALPHA=ALPHA)



print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss')
print_acc_loss(sdl,sda,tdl,tda, title="alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss')
print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN_every_plots')
test(net,target_dataloader)



"""Alexnet hyperparameters search"""

BATCH_SIZE = 256     
LR = 1e-2            
MOMENTUM = 0.9       
WEIGHT_DECAY = 5e-5   
NUM_EPOCHS = 30      
STEP_SIZE = 10       
GAMMA = 0.1       

tests = []
first_attempt = {
'LR' : LR,
'WEIGHT_DECAY' : WEIGHT_DECAY,
'STEP_SIZE': STEP_SIZE,
'GAMMA' : GAMMA,
'accuracy' : 0.470703125
}
tests.append(first_attempt)
ress = [0.470703125]


best_params = {}

import random
num_iters=8

for i in range(num_iters):
    print(f'Iteration {i+1} / {num_iters}')
    lr = 10**(-random.randint(3,5))
    wd = 5*10**(-random.randint(4,6))
    gamma = random.uniform(0.1,0.5)
    #alpha = random.uniform(0.01,0.5)
    s = f'{lr}_{wd}_{gamma}'
    net = torchvision.models.alexnet(pretrained=True) 
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES) 
    criterion = nn.CrossEntropyLoss() 
    parameters_to_optimize = net.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=wd)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=gamma)
    tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="/content/drive/My Drive/alexnet_noDANN_pretrained_"+s)
    print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained_"+s)
    res = test(net,target_dataloader)

    result = {  'LR' : lr,
                'WEIGHT_DECAY' : wd,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : gamma,
                'accuracy' : res}

    tests.append(result)
    if res > max(ress):
        best_params = result
    ress.append(res)


print(f"The highest accuracy is: {max(ress)} for params: {best_params}")

print(f"The highest accuracy is: {max(ress)} for params: {best_params}")

"""DANN hyperparameters search"""

BATCH_SIZE = 256     
LR = 1e-2            
MOMENTUM = 0.9       
WEIGHT_DECAY = 5e-5   
NUM_EPOCHS = 30      
STEP_SIZE = 10       
GAMMA = 0.1       
ALPHA = 0.1

src_dataloader = DataLoader(src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
criterion = nn.CrossEntropyLoss() 
domain_criterion = nn.CrossEntropyLoss()

first_attempt = {
'LR' : LR,
'WEIGHT_DECAY' : WEIGHT_DECAY,
'STEP_SIZE': STEP_SIZE,
'GAMMA' : GAMMA,
'ALPHA':ALPHA,
'accuracy' : 0.3828125
}

best_params = {}

import random
num_iters=8

for i in range(num_iters):    
    print(f'Iteration {i+1} / {num_iters}')
    lr = 10**(-random.randint(3,5))
    wd = 5*10**(-random.randint(4,6))
    gamma = random.uniform(0.1,0.5)
    alpha = random.uniform(0.01,0.5)
    s = f'{lr}_{wd}_{gamma}_{alpha}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=lr, momentum=MOMENTUM, weight_decay=wd)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=gamma)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=alpha)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)

    result = {  'LR' : lr,
                'WEIGHT_DECAY' : wd,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : gamma,
                'ALPHA' : alpha,
                'accuracy' : res}

    tests.append(result)
    if res > max(ress):
        best_params = result
    ress.append(res)


print(f"The highest accuracy is: {max(ress)} for params: {best_params}")

BATCH_SIZE = 256     
LR = 1e-2            
MOMENTUM = 0.9       
WEIGHT_DECAY = 5e-5   
NUM_EPOCHS = 30      
STEP_SIZE = 10       
GAMMA = 0.1       

parameters = {
    'LR' : [1e-1,1e-3],
    'WEIGHT_DECAY' : [5e-4,5e-6],
    'STEP_SIZE': [5,10,15],
    'GAMMA' : [0.05,0.3,0.5]
}
tests = []
first_attempt = {
'LR' : LR,
'WEIGHT_DECAY' : WEIGHT_DECAY,
'STEP_SIZE': STEP_SIZE,
'GAMMA' : GAMMA,
'accuracy' : 0.470703125
}
tests.append(first_attempt)
ress = [0.470703125]
for lra in parameters['LR']:
    s = f'lr_{lra}'
    net = torchvision.models.alexnet(pretrained = True)
    net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
    criterion = nn.CrossEntropyLoss()
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=lra, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
    tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="/content/drive/My Drive/alexnet_noDANN_pretrained_"+s)
    print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained_"+s)
    res = test(net,target_dataloader)
    
    result = {  'LR' : lra,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      LR = lra
    ress.append(res)

print(tests)
print(ress)

for wd in parameters['WEIGHT_DECAY']:
    s = f'wd_{wd}'
    net = torchvision.models.alexnet(pretrained = True)
    net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
    criterion = nn.CrossEntropyLoss()
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=wd)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
    tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="/content/drive/My Drive/alexnet_noDANN_pretrained_"+s)
    print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained_"+s)
    res = test(net,target_dataloader)
    
    result = {  'LR' : LR,
                'WEIGHT_DECAY' : wd,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      print("new best found")
      WEIGHT_DECAY=wd
    ress.append(res)

print(tests)
print(ress)

for st in parameters['STEP_SIZE']:
    s = f'st_{st}'
    net = torchvision.models.alexnet(pretrained = True)
    net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
    criterion = nn.CrossEntropyLoss()
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=st, gamma=GAMMA)
    tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="/content/drive/My Drive/alexnet_noDANN_pretrained_"+s)
    print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained_"+s)
    res = test(net,target_dataloader)
    
    result = {  'LR' : LR,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': st,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      print("new best found")
      STEP_SIZE = st
    ress.append(res)

print(tests)
print(ress)


for g in parameters['GAMMA']:
    s = f'g_{g}'
    net = torchvision.models.alexnet(pretrained = True)
    net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
    criterion = nn.CrossEntropyLoss()
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=g)
    tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="/content/drive/My Drive/alexnet_noDANN_pretrained_"+s)
    print_acc_loss(tl,ta,vl,va,"alexnet_noDANN_pretrained_"+s)
    res = test(net,target_dataloader)
    result = {  'LR' : LR,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : g,
                'accuracy' : res}
    tests.append(result)
    
    if res > max(ress):
      GAMMA = g
    ress.append(res)

print(tests)
print(ress)

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
BATCH_SIZE = 256     
LR = 1e-2            
MOMENTUM = 0.9       
WEIGHT_DECAY = 5e-5   
NUM_EPOCHS = 30      
STEP_SIZE = 10       
GAMMA = 0.1       
ALPHA = 0.1
parameters = {
    'ALPHA' : [0.05,0.2],
    'LR' : [1e-1,1e-3],
    'WEIGHT_DECAY' : [5e-4,5e-6],
    'STEP_SIZE': [5,10,15],
    'GAMMA' : [0.05,0.3,0.5]
}

first_attempt = {
'ALPHA':ALPHA,
'LR' : LR,
'WEIGHT_DECAY' : WEIGHT_DECAY,
'STEP_SIZE': STEP_SIZE,
'GAMMA' : GAMMA,
'accuracy' : 0.38
}

tests.append(first_attempt)
ress = [0.38]

src_dataloader = DataLoader(src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
criterion = nn.CrossEntropyLoss()
domain_criterion = nn.CrossEntropyLoss()

for lra in parameters['LR']:
    s = f'lr_{lra}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=lra, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=ALPHA)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)
    result = {  'ALPHA' : ALPHA,
                'LR' : lra,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      LR = lra
    ress.append(res)

print(tests)
print(ress)

for wd in parameters['WEIGHT_DECAY']:
    s = f'wd_{wd}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=wd)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=ALPHA)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)
    result = {  'ALPHA' : ALPHA,
                'LR' : LR,
                'WEIGHT_DECAY' : wd,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      WEIGHT_DECAY=wd
    ress.append(res)

print(tests)
print(ress)

for st in parameters['STEP_SIZE']:
    s = f'st_{st}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=st, gamma=GAMMA)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=ALPHA)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)
    result = {  'ALPHA' : ALPHA,
                'LR' : LR,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': st,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      STEP_SIZE = st
    ress.append(res)

print(tests)
print(ress)


for g in parameters['GAMMA']:
    s = f'lr_{lra}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=g)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=ALPHA)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)
    result = {  'ALPHA' : ALPHA,
                'LR' : LR,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : g,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      GAMMA = g
    ress.append(res)

print(tests)
print(ress)

for a in parameters['ALPHA']:
    s = f'a_{a}'
    net = alexnet(pretrained=True)
    net.classifier[6] = nn.Linear(4096, NUM_CLASSES)
    net.domain_classifier[6] = nn.Linear(4096,NUM_DOMAINS)
    parameters_to_optimize = net.classifier.parameters() 
    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
    totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,net = train_dann(net,src_dataloader=src_dataloader,target_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN"+s,ALPHA=a)
    print_acc_loss(tl,ta,vl,va,"alexnet_DANN class",label1 = 'source accuracy', label2 = 'target accuracy', label3 = 'source loss',label4= 'target loss'+s)
    print_acc_loss(sdl,sda,tdl,tda, "alexnet_DANN domain",label1 = 'source domain accuracy', label2 = 'target domain accuracy', label3 = 'source domain loss',label4= 'target domain loss'+s)
    print_DANN_acc_loss(totl,tota,dl,da,tl,ta,sdl,sda,tdl,tda,vl,va,title = 'DANN every plots'+s)
    res = test(net,target_dataloader)
    result = {  'ALPHA' : a,
                'LR' : LR,
                'WEIGHT_DECAY' : WEIGHT_DECAY,
                'STEP_SIZE': STEP_SIZE,
                'GAMMA' : GAMMA,
                'accuracy' : res}
    tests.append(result)
    if res > max(ress):
      ALPHA = a
    ress.append(res)


print(tests)
print(ress)

!mv *.png /content/drive/My\ Drive/

rs_alexnet = []
rs_dann = []
for image in os.listdir('/content/drive/My Drive'):
    if image.endswith('.png'):
        if image.startswith('alexnet_noDANN_pretrained_0.0'):
                data = image.split('_')
                dic = { 'LR' : data[3],
                        'WEIGHT_DECAY' : data[4],
                        'STEP_SIZE': 10,
                        'GAMMA' : data[5],
                        'accuracy' : 0}
                #model = torchvision.models.alexnet()
                #model.classifier[6] = nn.Linear(4096, NUM_CLASSES)
                mp = '/content/drive/My Drive/' + "_".join(image.split('_')[:-1])
                model = torch.load(mp)#.load_state_dict(torch.load(mp))
                model.eval()
                res = test(model,target_dataloader)
                dic['accuracy'] = res
                rs_alexnet.append(dic)

print(rs_alexnet)
print(rs_dann)

rs_dann = []
for image in os.listdir('/content/drive/My Drive'):
    if image.endswith('.png'):
        if image.startswith('DANN'):
            data = image.split('plots')[1]
            data = data.split('_')
            if len(data) > 4:
                dic = { 'ALPHA' : data[3],
                        'LR' : data[0],
                        'WEIGHT_DECAY' : data[1],
                        'STEP_SIZE': 10,
                        'GAMMA' : data[2],
                        'accuracy' : 0}
                mp = '/content/drive/My Drive/alexnet_DANN' + "_".join(data[:-2])
                model = torch.load(mp)#.load_state_dict(torch.load(mp))
                model.eval()
                res = test(model,target_dataloader)
                dic['accuracy'] = res
                rs_dann.append(dic)
print(rs_dann)

BATCH_SIZE = 256
src_dataloader = DataLoader(src_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)
target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
net = alexnet(pretrained = True,num_classes = NUM_CLASSES,num_domains = 2) # Loading AlexNet model
# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes
# We need 101 outputs for Caltech-101
#net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer
                                                 # The convolutional layer is nn.Conv2d
criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy

# Choose parameters to optimize
# To access a different set of parameters, you have to access submodules of AlexNet
# (nn.Module objects, like AlexNet, implement the Composite Pattern)
# e.g.: parameters of the fully connected layers: net.classifier.parameters()
# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) 
parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet

# Define optimizer
# An optimizer updates the weights based on loss
# We use SGD with momentum
optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)

# Define scheduler
# A scheduler dynamically changes learning rate
# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs
# It is mandatory to study torchvision.models.alexnet source code
for p in net.parameters():
    p.requires_grad = True

total_params = sum(p.numel() for p in net.parameters())
print(f'{total_params:,} total parameters.')
total_trainable_params = sum(
    p.numel() for p in net.parameters() if p.requires_grad)
print(f'{total_trainable_params:,} training parameters.')



tl,ta,vl,va,net = train_dann(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="./alexnet_DANN",ALPHA=ALPHA)

"""**Test**"""

net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda
net.train(False) # Set Network to evaluation mode

running_corrects = 0
for images, labels in tqdm(target_dataloader):
  images = images.to(DEVICE)
  labels = labels.to(DEVICE)

  # Forward Pass
  outputs = net(images)

  # Get predictions
  _, preds = torch.max(outputs.data, 1)

  # Update Corrects
  running_corrects += torch.sum(preds == labels.data).data.item()

# Calculate Accuracy
accuracy = running_corrects / float(len(target_dataset))

print('Test Accuracy: {}'.format(accuracy))

net = alexnet() #num_classes = NUM_CLASSES)#,num_domains = 2) # Loading AlexNet model
net.classifier[6] = nn.Linear(4096,NUM_CLASSES)
# AlexNet has 1000 output neurons, corresponding to the 1000 ImageNet's classes
# We need 101 outputs for Caltech-101
#net.classifier[6] = nn.Linear(4096, NUM_CLASSES) # nn.Linear in pytorch is a fully connected layer
                                                 # The convolutional layer is nn.Conv2d
criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy

# Choose parameters to optimize
# To access a different set of parameters, you have to access submodules of AlexNet
# (nn.Module objects, like AlexNet, implement the Composite Pattern)
# e.g.: parameters of the fully connected layers: net.classifier.parameters()
# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) 
parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet

# Define optimizer
# An optimizer updates the weights based on loss
# We use SGD with momentum
optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)

# Define scheduler
# A scheduler dynamically changes learning rate
# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)
# We just changed the last layer of AlexNet with a new fully connected layer with 101 outputs
# It is mandatory to study torchvision.models.alexnet source code
for p in net.parameters():
    p.requires_grad = True

total_params = sum(p.numel() for p in net.parameters())
print(f'{total_params:,} total parameters.')
total_trainable_params = sum(
    p.numel() for p in net.parameters() if p.requires_grad)
print(f'{total_trainable_params:,} training parameters.')



tl,ta,vl,va,net = train(net,train_dataloader=src_dataloader,val_dataloader=target_dataloader,checkpoint_path="./alexnet_noDANN")
print_acc_loss(tl,ta,vl,va,"alexnet_noDANN")
test(net,target_dataloader)